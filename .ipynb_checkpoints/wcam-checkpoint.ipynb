{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageTk\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40, device=device) # keep_all=False\n",
    "mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40, device=device) # keep_all=True\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from folder\n",
    "\n",
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder('photos') # photos folder path\n",
    "idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn)\n",
    "\n",
    "name_list = [] # list of names corresponding to cropped photos\n",
    "embedding_list = [] # list of embedding matrix after conversion from cropped faces to embedding matrix using resnet\n",
    "\n",
    "for img, idx in loader:\n",
    "    face, prob = mtcnn0(img, return_prob=True)\n",
    "    if face is not None and prob>0.9:\n",
    "        emb = resnet(face.unsqueeze(0).to(device))\n",
    "        embedding_list.append(emb.cpu().detach())\n",
    "        name_list.append(idx_to_class[idx])\n",
    "        \n",
    "\n",
    "# save data\n",
    "data = [embedding_list, name_list]\n",
    "torch.save(data, 'data.pt') # saving data.pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting...\n",
      "[INFO] saved 2021-02-01_23-24-34.jpg\n",
      "[INFO] start recording 2021-02-01_23-25-25.mp4\n",
      "[INFO] stop recording\n",
      "[INFO] closing...\n"
     ]
    }
   ],
   "source": [
    "#using webcame recognize face\n",
    "#loading data.pt file\n",
    "load_data = torch.load('data.pt') \n",
    "embedding_list = load_data[0] \n",
    "name_list = load_data[1]\n",
    "\n",
    "PROBABILITY_THRESHOLD = 0.9\n",
    "MINDIST_THRESHOLD = 1.1\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.screenshot_path = \"screenshots\"                     # store screenshot path\n",
    "        self.video_path = \"videos\"                               # store screenshot path\n",
    "        self.current_image = None                                # current image from the camera\n",
    "        \n",
    "        self.width = int(self.vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        self.writer = None\n",
    "        self.record_status = False\n",
    "\n",
    "        self.root = tk.Tk()                                      # initialize root window\n",
    "        self.root.title(\"Face Recognition\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)  # self.destructor function gets fired when the window is closed\n",
    "\n",
    "        self.panel = tk.Label(self.root)                         # initialize image panel\n",
    "        self.panel.pack(padx=10, pady=10)\n",
    "\n",
    "        btn_screenshot = tk.Button(self.root, text=\"Take picture!\", command=self.take_snapshot)\n",
    "        btn_screenshot.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "        \n",
    "        btn_start_record = tk.Button(self.root, text=\"Record\", command=self.start_record)\n",
    "        btn_start_record.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "        \n",
    "        btn_stop_record = tk.Button(self.root, text=\"Stop Recording\", command=self.stop_record)\n",
    "        btn_stop_record.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.video_loop()\n",
    "\n",
    "    def video_loop(self):\n",
    "        ready, frame = self.vs.read()                            # read frame from video stream\n",
    "        img = Image.fromarray(frame)\n",
    "        img_cropped_list, prob_list = mtcnn(img, return_prob=True)        \n",
    "              \n",
    "        if ready:  # frame captured without any errors\n",
    "            if img_cropped_list is not None:\n",
    "                boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "                for i, prob in enumerate(prob_list):\n",
    "                    if prob>PROBABILITY_THRESHOLD:\n",
    "                        emb = resnet(img_cropped_list[i].unsqueeze(0).to(device)).cpu().detach() \n",
    "\n",
    "                        dist_list = []         # list of matched distances, minimum distance is used to identify the person\n",
    "\n",
    "                        for idx, emb_db in enumerate(embedding_list):\n",
    "                            dist = torch.dist(emb, emb_db, 2).item()\n",
    "                            dist_list.append(dist)\n",
    "\n",
    "                        softmax_list = np.exp(dist_list) / np.sum(np.exp(dist_list), axis=0)\n",
    "                        min_dist = min(dist_list)\n",
    "                        min_dist_idx = dist_list.index(min_dist)                  # get minumum dist index\n",
    "                        confidence_score = 1 - softmax_list[min_dist_idx]\n",
    "                        name = name_list[min_dist_idx]                            # get name corrosponding to minimum dist\n",
    "\n",
    "                        box = boxes[i].astype(int)\n",
    "\n",
    "                        if min_dist<MINDIST_THRESHOLD:\n",
    "                            frame = cv2.putText(frame, name+' '+str(\"%.3f\" % confidence_score), (box[0],box[1]), cv2.FONT_HERSHEY_TRIPLEX, 1, (0,255,0), 1, cv2.LINE_AA)\n",
    "                        else:\n",
    "                            frame = cv2.putText(frame, 'unknown', (box[0],box[1]), cv2.FONT_HERSHEY_TRIPLEX, 1, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "                        frame = cv2.rectangle(frame, (box[0],box[1]) , (box[2],box[3]), (255,0,0), 2)\n",
    "            \n",
    "            if self.record_status:\n",
    "                self.writer.write(frame)\n",
    "            cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            self.current_image = Image.fromarray(cv2image)\n",
    "            imgtk = ImageTk.PhotoImage(image=self.current_image)\n",
    "            self.panel.imgtk = imgtk                                                   # anchor imgtk so it does not be deleted by garbage-collector\n",
    "            self.panel.config(image=imgtk)                                             # show the image\n",
    "        self.root.after(30, self.video_loop)                                           # call the same function after 30 milliseconds\n",
    "\n",
    "    def take_snapshot(self):\n",
    "        ts = datetime.datetime.now()\n",
    "        filename = \"{}.jpg\".format(ts.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "        p = os.path.join(self.screenshot_path, filename)\n",
    "        self.current_image.save(p, \"JPEG\")\n",
    "        print(\"[INFO] saved {}\".format(filename))\n",
    "        \n",
    "    def start_record(self):\n",
    "        ts = datetime.datetime.now()\n",
    "        video_name = \"{}.mp4\".format(ts.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "        path = os.path.join(self.video_path, video_name)\n",
    "        self.writer = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*'DIVX'), 20, (self.width,self.height))\n",
    "        self.record_status = True\n",
    "        print(\"[INFO] start recording {}\".format(video_name))\n",
    "    \n",
    "    def stop_record(self):\n",
    "        self.writer.release()\n",
    "        self.writer = None\n",
    "        self.record_status = False\n",
    "        print(\"[INFO] stop recording\")\n",
    "    \n",
    "    def destructor(self):\n",
    "        print(\"[INFO] closing...\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# start the app\n",
    "print(\"[INFO] starting...\")\n",
    "pba = Application()\n",
    "pba.root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
